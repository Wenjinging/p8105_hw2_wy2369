p8105_hw2_wy2369
================
Wenjing Yang
10/3/2022

# Problem 1

### Import and clean data

``` r
library(tidyverse)
library(readxl)
```

The process begins with data import, updates variable names, and selects
the columns that will be used in later parts fo this problem. Update
`entry` from `yes` / `no` to a logical variable using `ifelse`.

As part of data import, we specify that `Route` columns 8-11 should be
character for consistency with 1-7.

``` r
trans_ent = 
  read_csv(
    "./hw2data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

### Describe the dataset in a short paragraph.

Read data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`, and
clean it using `janitor::clean_names()`.The dataset contains
`line, station_name, station_latitude, station_longitude, route, entry, exit_only, vending, entrance_type, and ada`
variables. The resulting dataset has **1868** rows and **20** columns.

These data are not “tidy” because route number should be a variable, as
should route. That is, to obtain a tidy dataset we would need to convert
`route` variables from wide to long format.

### Explain how many distinct stations are there.

Use `distinct()` to select station name and line, and then obtain all
unique combinations. As a result, the number of rows in this dataset is
the number of unique stations. There are **465** distinct stations.

``` r
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 465 × 2
    ##    station_name             line    
    ##    <chr>                    <chr>   
    ##  1 25th St                  4 Avenue
    ##  2 36th St                  4 Avenue
    ##  3 45th St                  4 Avenue
    ##  4 53rd St                  4 Avenue
    ##  5 59th St                  4 Avenue
    ##  6 77th St                  4 Avenue
    ##  7 86th St                  4 Avenue
    ##  8 95th St                  4 Avenue
    ##  9 9th St                   4 Avenue
    ## 10 Atlantic Av-Barclays Ctr 4 Avenue
    ## # … with 455 more rows

### Explain how many stations are ADA compliant.

Use `filter()` as an initial step to find how many stations are ADA
cpmpliant. This produces a dataframe in which the number of rows is the
number of ADA compliant stations. Hence, **84** stations are ADA
compliant.

``` r
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 84 × 2
    ##    station_name                   line           
    ##    <chr>                          <chr>          
    ##  1 Atlantic Av-Barclays Ctr       4 Avenue       
    ##  2 DeKalb Av                      4 Avenue       
    ##  3 Pacific St                     4 Avenue       
    ##  4 Grand Central                  42nd St Shuttle
    ##  5 34th St                        6 Avenue       
    ##  6 47-50th Sts Rockefeller Center 6 Avenue       
    ##  7 Church Av                      6 Avenue       
    ##  8 21st St                        63rd Street    
    ##  9 Lexington Av                   63rd Street    
    ## 10 Roosevelt Island               63rd Street    
    ## # … with 74 more rows

### Compute the proportion of station entrances / exits without vending allow entrance.

First exclude station entrances that do not allow vending. Then, use
`entry` variable – this logical. Taking the mean will produce the
desired proportion, which is **0.3770492**.

``` r
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

    ## [1] 0.3770492

### Compute the stations that serve the A train and how many A train stations are ADA compliant.

Firstly, tidy the data as alluded to previously and convert `route` from
wide to long format by using `pivot_longer()`. After this step, we can
use tools from previous parts of the question. We get **60** stations
that serve A train and **17** of these stations are ADA compliant.

``` r
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 60 × 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # … with 50 more rows

``` r
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

    ## # A tibble: 17 × 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

# Problem 2

### Import, clean, and organize **Mr. Trash Wheel** sheet.

Use code `read_excel` to read, and `janitor::clean_names()` to clean
data from `Trash Wheel Collection Data.xlsx`. Omit non-data rows and
columns, and then round the number of sports balls to the nearest
integer. After that, convert the result to an integer variable by using
`as.integer`.

``` r
mr_trash_df = 
  read_excel(
    "./hw2data/Trash Wheel Collection Data.xlsx",
    sheet = "Mr. Trash Wheel",
    range = "A2:N550") %>% 
  janitor::clean_names() %>%
  drop_na (c(dumpster)) %>%
  mutate(sports_balls = round(sports_balls,digits = 0) )%>%
  mutate(sports_balls = as.integer(sports_balls) ,data_source = "mr_trash_wheel",year = as.integer(year))
```

### Import, clean, and organize **Professor Trash Wheel** sheet.

Use a similar process to organize the data from Professor Trash Wheel
sheet.

``` r
prof_trash_df = 
  read_excel(
    "./hw2data/Trash Wheel Collection Data.xlsx",
    sheet = "Professor Trash Wheel",
    range = "A2:M97") %>% 
  janitor::clean_names() %>%
  drop_na (c(dumpster)) %>%
  mutate(data_source = "prof_trash_wheel")
```

### Combine the two datasets.

Use code `bind_rows` to combine `mr_trash_df` and `prof_trash_df` , and
get `trash_tidy` dataset.

``` r
trash_tidy = 
  bind_rows(mr_trash_df,prof_trash_df) %>%
  janitor::clean_names() 

trash_tidy
```

    ## # A tibble: 641 × 15
    ##    dumpster month  year date                weight_tons volume…¹ plast…² polys…³
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>    <dbl>   <dbl>   <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31       18    1450    1820
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74       13    1120    1030
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45       15    2450    3100
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1        15    2380    2730
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06       18     980     870
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71       13    1430    2140
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91        8     910    1090
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7        16    3580    4310
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52       14    2400    2790
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76       18    1340    1730
    ## # … with 631 more rows, 7 more variables: cigarette_butts <dbl>,
    ## #   glass_bottles <dbl>, grocery_bags <dbl>, chip_bags <dbl>,
    ## #   sports_balls <int>, homes_powered <dbl>, data_source <chr>, and abbreviated
    ## #   variable names ¹​volume_cubic_yards, ²​plastic_bottles, ³​polystyrene

### Write a short description and answer questions.

In trash_tidy dataset, there are 15 key variables, for example month,
date, weight_tons, and glass_bottles. The data frame has **641** rows
and **15** columns.

``` r
weight_proTrash = 
  trash_tidy %>%
  filter(data_source == "prof_trash_wheel") 
  sum(weight_proTrash$weight_tons)
```

    ## [1] 190.12

The total weight of trash collected by Professor Trash Wheel is
**190.12**.

``` r
year_2020 = 
  trash_tidy %>%
  filter(data_source == "mr_trash_wheel", year == 2020)
  sum(year_2020$sports_balls)
```

    ## [1] 856

The total number of sports balls collected by Mr. Trash Wheel in 2020 is
**856**.

# Problem 3

### Read and clean data from `fivethirtyeight` datasets.

Use this code chunk to read and organize `pols-month.csv` dataset. Use
`separate()` to break up the variable **mon** into integer variables
year, month, and day; Use `month.abb` to replace month number with month
name. Create a president variable taking values “DEM” and “GOP”, and
remove prez_dem, prez_gop and the day variable in the dataset.

``` r
pols_month =
  read_csv("./fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year","month","day") ) %>%
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    month = month.abb[month],
    president = ifelse( prez_dem == 1, "DEM","GOP" )) %>%
  select(-prez_dem,-prez_gop,-day)
  
pols_month
```

    ## # A tibble: 822 × 9
    ##     year month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president
    ##    <int> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>    
    ##  1  1947 Jan        23      51     253      23      45     198 DEM      
    ##  2  1947 Feb        23      51     253      23      45     198 DEM      
    ##  3  1947 Mar        23      51     253      23      45     198 DEM      
    ##  4  1947 Apr        23      51     253      23      45     198 DEM      
    ##  5  1947 May        23      51     253      23      45     198 DEM      
    ##  6  1947 Jun        23      51     253      23      45     198 DEM      
    ##  7  1947 Jul        23      51     253      23      45     198 DEM      
    ##  8  1947 Aug        23      51     253      23      45     198 DEM      
    ##  9  1947 Sep        23      51     253      23      45     198 DEM      
    ## 10  1947 Oct        23      51     253      23      45     198 DEM      
    ## # … with 812 more rows

Use this code chunk to read and organize `snp.csv` dataset, and arrange
according to year and month, and organize so that year and month are the
leading columns.

``` r
snp_df =
  read_csv("./fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  mutate(date = as.Date(date, "%m/%d/%y")) %>%
  separate(date, into = c("year","month","day") ) %>%
  mutate(
    year = as.integer(year),
    year = ifelse(year > 2049, year-100, year),
    month = as.integer(month),
    day = as.integer(day)) %>%
  arrange(year, month) %>%
  mutate(month = month.abb[month])  %>%
  select(-day)

snp_df
```

    ## # A tibble: 787 × 3
    ##     year month close
    ##    <dbl> <chr> <dbl>
    ##  1  1950 Jan    17.0
    ##  2  1950 Feb    17.2
    ##  3  1950 Mar    17.3
    ##  4  1950 Apr    18.0
    ##  5  1950 May    18.8
    ##  6  1950 Jun    17.7
    ##  7  1950 Jul    17.8
    ##  8  1950 Aug    18.4
    ##  9  1950 Sep    19.5
    ## 10  1950 Oct    19.5
    ## # … with 777 more rows

Use this code chunk to read and organize `unemployment.csv` dataset.
This process will involve switching from “wide” to “long” format using
`pivot_longer()`.

``` r
unemploy_df =
  read_csv("./fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>%
  mutate(
    year = as.integer(year)) %>%
  pivot_longer(
    jan : dec,
    names_to = "month",
    values_to = "unemployment_rate"
  ) %>%
  mutate(month = str_to_title(month))
  
unemploy_df
```

    ## # A tibble: 816 × 3
    ##     year month unemployment_rate
    ##    <int> <chr>             <dbl>
    ##  1  1948 Jan                 3.4
    ##  2  1948 Feb                 3.8
    ##  3  1948 Mar                 4  
    ##  4  1948 Apr                 3.9
    ##  5  1948 May                 3.5
    ##  6  1948 Jun                 3.6
    ##  7  1948 Jul                 3.6
    ##  8  1948 Aug                 3.9
    ##  9  1948 Sep                 3.8
    ## 10  1948 Oct                 3.7
    ## # … with 806 more rows

### Join the datasets.

Merging `snp_df` into `pols_month`, and merging `unemploy_df` into the
result using this code chunk, and get the tidy dataset
`snp_pols_unemlop_tidy`.

``` r
snp_pols_tidy = 
  left_join(pols_month, snp_df, by = c("year","month"))

snp_pols_unemlop_tidy = 
  left_join(snp_pols_tidy, unemploy_df,by = c("year","month"))

snp_pols_unemlop_tidy
```

    ## # A tibble: 822 × 11
    ##     year month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem president close
    ##    <dbl> <chr>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>     <dbl>
    ##  1  1947 Jan        23      51     253      23      45     198 DEM          NA
    ##  2  1947 Feb        23      51     253      23      45     198 DEM          NA
    ##  3  1947 Mar        23      51     253      23      45     198 DEM          NA
    ##  4  1947 Apr        23      51     253      23      45     198 DEM          NA
    ##  5  1947 May        23      51     253      23      45     198 DEM          NA
    ##  6  1947 Jun        23      51     253      23      45     198 DEM          NA
    ##  7  1947 Jul        23      51     253      23      45     198 DEM          NA
    ##  8  1947 Aug        23      51     253      23      45     198 DEM          NA
    ##  9  1947 Sep        23      51     253      23      45     198 DEM          NA
    ## 10  1947 Oct        23      51     253      23      45     198 DEM          NA
    ## # … with 812 more rows, and 1 more variable: unemployment_rate <dbl>

### Explain the resulting dataset.

For `pols_month`, it has 822 rows and 9 columns. There are **9**
distinct variables which include year, month, gov_gop, sen_gop, rep_gop,
gov_dem, sen_demm, rep_dem, and president. The range of year in the
dataset is **from 1947 to 2015**.

For `snp_df`, it has 787 rows and 3 columns. There are **3** distinct
variables which include year, month, and close in the dataset. The range
of year is **from 1950 to 2015**.

For `unemploy_df`, it has 816 rows and 3 columns. There are **3**
distinct variables which include year, month, and unemployment_rate in
the dataset. The range of year is **from 1948 to 2015**.

Use code `left_join()` to combine these datasets. In the resulting
dataset `snp_pols_unemlop_tidy`, it has 822 rows and 11 columns, and
**11** key variables which are year, month, gov_gop, sen_gop, rep_gop,
gov_dem, sen_demm, rep_dem, president, close, and unemployment_rate. The
range of year in the resulting dataset is **from 1947 to 2015**.
